
1) ¿Cuál es la diferencia entre aprendizaje supervisado y no supervisado en machine learning?

El aprendizaje supervisado necesita para el entrenamiento de datos etiquetados. Ejemplo, para realizar una clasificación primero se deben etiquetar los datos a utilizar.
En cambio, el no supervisado, no necesita etiquetar los datos de entrada de forma explícita.

2) Explique el trade-off sesgo-varianza.

Se refiere al equilibrio entre la capacidad de un modelo para ajustarse bien a los datos de entrenamiento (bajo sesgo) y su capacidad para generalizar a datos nuevos (baja varianza).
Si el modelo tiene un sesgo alto es lo mismo que decir que el modelo tiene una complejidad baja(es muy simple). A medida que aumenta la complejidad el sesgo disminuye.
Alto sesgo: cuando un modelo tiene un alto sesgo, tiende a no ajustarse a los datos, lo que significa que no captura los patrones subyacentes.
Alta varianza: cuando un modelo tiene una alta varianza, es demasiado complejo y se ajusta al ruido de los datos, lo que lleva a una generalización deficiente.
Encontrar el equilibrio adecuado entre sesgo y varianza es crucial para crear modelos que funcionen bien tanto con datos de entrenamiento como de prueba.

3) ¿Qué es el sobreajuste y cómo se puede prevenir?

El sobreajuste, también conocido como overfitting en inglés, es un fenómeno donde un modelo se ajusta demasiado bien a los datos de entrenamiento, pero tiene un rendimiento deficiente cuando se enfrenta a datos nuevos, es decir,
datos que no ha visto durante el entrenamiento.

Acciones para prevenir: 

- Simplificar el modelo (por ejemplo, reducir su complejidad).
- Utilice técnicas de regularización
- Emplear validación cruzada(Cross Validation) para evaluar el rendimiento del modelo.
- Selección de características(Feature selection): Seleccionar cuidadosamente las características más relevantes para el problema en cuestión
y eliminar aquellas que puedan introducir ruido en el modelo puede ayudar a prevenir el sobreajuste.

4) ¿Qué es la validación cruzada (Cross Validation)  y por qué es importante?

La validación cruzada es una técnica utilizada para evaluar el desempeño de un modelo. Implica dividir los datos en múltiples subconjuntos, llamados "folds" o "pliegues", y luego utilizar estos subconjuntos de manera rotativa para entrenar y evaluar el modelo.
La validación cruzada es importante porque proporciona una estimación más sólida del rendimiento de un modelo, lo que ayuda a detectar problemas como el sobreajuste. 


5) Explicar cómo funciona una curva ROC.

La curva ROC compara la Tasa de Verdaderos Positivos y la Tasa de Falsos Positivos, esta se usa para medir el rendimiento (o la efectividad, en su mas amplio sentido) del clasificador a través de distintos metodos, en este caso se emplea el AUC - ROC (área bajo la curva ROC).
El ROC es una curva de probabilidad y el AUC representa el grado de separabilidad, este indica en que medida el modelo es capaz de distinguir entre clases. 
Cuanto más abraza la curva la esquina superior izquierda del gráfico, mejor lo hace el modelo para clasificar los datos en categorías. 
Cuanto más cerca esté el AUC de 1, mejor será el modelo. Un modelo con un AUC igual a 0.5 no es mejor que un modelo que hace clasificaciones aleatorias. 
